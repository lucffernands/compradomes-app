name: Scraper e Deploy

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */2 * * *" # a cada 2h

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout do repo
      - name: Checkout repo
        uses: actions/checkout@v3

      # 2️⃣ Configura Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      # 3️⃣ Instala dependências do scraper
      - name: Instalar dependências
        working-directory: scrapers
        run: |
          npm install
          # Caso precise instalar jsdom manualmente:
          npm install jsdom

      # 4️⃣ Roda o scraper
      - name: Rodar scraper
        working-directory: scrapers
        run: node scrape.js

      # 5️⃣ Converte fragments HTML para JSON
      - name: Build fragments
        working-directory: scrapers
        run: node build-fragments.js

      # 6️⃣ Publica no GitHub Pages
      - name: Deploy para GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_branch: gh-pages
          publish_dir: ./site
