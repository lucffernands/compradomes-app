name: Scraper e Deploy

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */2 * * *" # a cada 2h

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout do repo
      - name: Checkout repo
        uses: actions/checkout@v3

      # 2️⃣ Configura Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      # 3️⃣ Instala dependências do scraper
      - name: Instalar dependências
        working-directory: scrapers
        run: |
          npm install
          npm install jsdom

      # 4️⃣ Roda o scraper
      - name: Rodar scraper
        working-directory: scrapers
        run: node scrape.js

      # 5️⃣ Copia o prices.json para o site
      - name: Copiar prices.json para o site
        run: |
          mkdir -p site/data
          cp data/prices.json site/data/prices.json

      # 6️⃣ Converte fragments HTML para JSON
      - name: Build fragments
        working-directory: scrapers
        run: node build-fragments.js

      # 7️⃣ Publica no GitHub Pages
      - name: Deploy para GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_branch: gh-pages
          publish_dir: ./site
